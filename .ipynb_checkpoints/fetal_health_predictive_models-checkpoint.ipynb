{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "928897af-c0e9-488f-836b-748e738efb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ac850c0-cb31-4ce8-9cb3-323cb389574c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('fetal_health.csv')\n",
    "X = data.drop(columns=['fetal_health'])\n",
    "y = data['fetal_health']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8298dd3d-ffa7-44c1-9466-c499d4b2c909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Evaluation Metrics:\n",
      "Accuracy: 0.87\n",
      "Precision: 0.88\n",
      "Recall: 0.87\n",
      "F1 Score: 0.87\n",
      "\n",
      "Confusion Matrix:\n",
      "[[314  17   1]\n",
      " [ 20  37   2]\n",
      " [  3  11  21]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.93      0.95      0.94       332\n",
      "         2.0       0.57      0.63      0.60        59\n",
      "         3.0       0.88      0.60      0.71        35\n",
      "\n",
      "    accuracy                           0.87       426\n",
      "   macro avg       0.79      0.72      0.75       426\n",
      "weighted avg       0.88      0.87      0.87       426\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),        # Standardize the features\n",
    "    ('logreg', LogisticRegression(solver='liblinear', max_iter=500))     # Logistic Regression Model\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Step 4: Make predictions\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Step 5: Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Print results\n",
    "print(\"Model Evaluation Metrics:\")\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63a6e46c-259e-4367-8e5a-cce73f8a01a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Model Evaluation Metrics:\n",
      "Accuracy: 0.92\n",
      "Precision: 0.92\n",
      "Recall: 0.92\n",
      "F1 Score: 0.92\n",
      "\n",
      "Confusion Matrix:\n",
      "[[325   5   2]\n",
      " [ 16  40   3]\n",
      " [  3   3  29]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.94      0.98      0.96       332\n",
      "         2.0       0.83      0.68      0.75        59\n",
      "         3.0       0.85      0.83      0.84        35\n",
      "\n",
      "    accuracy                           0.92       426\n",
      "   macro avg       0.88      0.83      0.85       426\n",
      "weighted avg       0.92      0.92      0.92       426\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize the Random Forest classifier\n",
    "rf_model = RandomForestClassifier(random_state=42, n_estimators=100)  # You can adjust n_estimators for optimization\n",
    "\n",
    "# Train the Random Forest model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions with the Random Forest model\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the Random Forest model\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "precision_rf = precision_score(y_test, y_pred_rf, average='weighted')\n",
    "recall_rf = recall_score(y_test, y_pred_rf, average='weighted')\n",
    "f1_rf = f1_score(y_test, y_pred_rf, average='weighted')\n",
    "conf_matrix_rf = confusion_matrix(y_test, y_pred_rf)\n",
    "class_report_rf = classification_report(y_test, y_pred_rf)\n",
    "\n",
    "print(\"Random Forest Model Evaluation Metrics:\")\n",
    "print(f\"Accuracy: {accuracy_rf:.2f}\")\n",
    "print(f\"Precision: {precision_rf:.2f}\")\n",
    "print(f\"Recall: {recall_rf:.2f}\")\n",
    "print(f\"F1 Score: {f1_rf:.2f}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix_rf)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(class_report_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64f0af86-3ca2-4901-9969-0d5ab7dd9470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Model Evaluation Metrics:\n",
      "Accuracy: 0.90\n",
      "Precision: 0.90\n",
      "Recall: 0.90\n",
      "F1 Score: 0.90\n",
      "\n",
      "Confusion Matrix:\n",
      "[[317  13   2]\n",
      " [ 16  38   5]\n",
      " [  5   1  29]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.94      0.95      0.95       332\n",
      "         2.0       0.73      0.64      0.68        59\n",
      "         3.0       0.81      0.83      0.82        35\n",
      "\n",
      "    accuracy                           0.90       426\n",
      "   macro avg       0.82      0.81      0.82       426\n",
      "weighted avg       0.90      0.90      0.90       426\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "# Initialize the Decision Tree classifier\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Train the Decision Tree model\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions with the Decision Tree model\n",
    "y_pred_dt = dt_model.predict(X_test)\n",
    "\n",
    "# Evaluate the Decision Tree model\n",
    "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
    "precision_dt = precision_score(y_test, y_pred_dt, average='weighted')\n",
    "recall_dt = recall_score(y_test, y_pred_dt, average='weighted')\n",
    "f1_dt = f1_score(y_test, y_pred_dt, average='weighted')\n",
    "conf_matrix_dt = confusion_matrix(y_test, y_pred_dt)\n",
    "class_report_dt = classification_report(y_test, y_pred_dt)\n",
    "\n",
    "print(\"Decision Tree Model Evaluation Metrics:\")\n",
    "print(f\"Accuracy: {accuracy_dt:.2f}\")\n",
    "print(f\"Precision: {precision_dt:.2f}\")\n",
    "print(f\"Recall: {recall_dt:.2f}\")\n",
    "print(f\"F1 Score: {f1_dt:.2f}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix_dt)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(class_report_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33ceea6c-1fc0-46a7-9615-c168430011be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 3.2716\n",
      "Epoch [2/20], Loss: 0.4149\n",
      "Epoch [3/20], Loss: 0.4219\n",
      "Epoch [4/20], Loss: 0.5701\n",
      "Epoch [5/20], Loss: 0.3886\n",
      "Epoch [6/20], Loss: 0.4490\n",
      "Epoch [7/20], Loss: 0.4483\n",
      "Epoch [8/20], Loss: 0.3524\n",
      "Epoch [9/20], Loss: 0.3966\n",
      "Epoch [10/20], Loss: 0.3354\n",
      "Epoch [11/20], Loss: 0.3270\n",
      "Epoch [12/20], Loss: 0.3397\n",
      "Epoch [13/20], Loss: 0.3118\n",
      "Epoch [14/20], Loss: 0.3235\n",
      "Epoch [15/20], Loss: 0.3651\n",
      "Epoch [16/20], Loss: 0.2995\n",
      "Epoch [17/20], Loss: 0.3133\n",
      "Epoch [18/20], Loss: 0.2981\n",
      "Epoch [19/20], Loss: 0.3391\n",
      "Epoch [20/20], Loss: 0.3287\n",
      "Neural Network Model Evaluation Metrics:\n",
      "Accuracy: 0.87\n",
      "Precision: 0.86\n",
      "Recall: 0.87\n",
      "F1 Score: 0.86\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.98      0.93       332\n",
      "           1       0.64      0.39      0.48        59\n",
      "           2       0.92      0.66      0.77        35\n",
      "\n",
      "    accuracy                           0.87       426\n",
      "   macro avg       0.82      0.68      0.73       426\n",
      "weighted avg       0.86      0.87      0.86       426\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Load and Prepare Data\n",
    "# Assume data is loaded in a DataFrame named `data` and target column is 'fetal_health'\n",
    "# Separate features and target\n",
    "X = data.drop(columns=['fetal_health']).values\n",
    "y = data['fetal_health'].values - 1  # Assuming labels are 1, 2, 3, shift to 0, 1, 2 for PyTorch\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "# Create DataLoader\n",
    "train_data = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_data = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=32)\n",
    "\n",
    "# Step 2: Define the Neural Network\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "input_size = X_train.shape[1]\n",
    "hidden_size = 512\n",
    "num_classes = len(np.unique(y))  # Assuming 3 classes for fetal health\n",
    "model = NeuralNet(input_size, hidden_size, 3)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Step 3: Train the Neural Network\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        # Forward pass\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n",
    "\n",
    "# Step 4: Evaluate the Model\n",
    "model.eval()\n",
    "y_pred_list = []\n",
    "with torch.no_grad():\n",
    "    for X_batch, _ in test_loader:\n",
    "        outputs = model(X_batch)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        y_pred_list.append(predicted)\n",
    "\n",
    "y_pred = torch.cat(y_pred_list).cpu().numpy()\n",
    "y_true = y_test_tensor.cpu().numpy()\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred, average='weighted')\n",
    "recall = recall_score(y_true, y_pred, average='weighted')\n",
    "f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "class_report = classification_report(y_true, y_pred)\n",
    "\n",
    "print(\"Neural Network Model Evaluation Metrics:\")\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e987edb9-ffb3-4140-a020-d219fe2f66a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
